Machine Learning

Linear Regression with one Variable:

Training set: 
    Notation:   
        m = Number of Training examples.
        x's = Input variable/Features.
        y's = Output variable/target variable.
        (x,y) = one training example or one raw of training example or one set of training example.


Process: 
    Trianing Set ==> Learning Algorithm ==> (h) Hypothesis



Ab humko curve me lowest point me aana hai, matlab ekdam deep me, sabse nichle portion me. waha phuchenge to mera Hypothesis solid baithega house size to price ratio me. jiska hum price pata karna chah rahe hai.


Deep ke aane ke process me: 
    If α is too small. gradient descent can be slow.

    If α is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge.


    Gradient descent can converge to a local minimum, even with the learning rate α fixed.

    As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease α over time.



"Batch" Gradient Descent:

    Batch: Each step of gradient descent uses all the training examples.






